{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Data Science Capstone Project\n",
    "## Introduction\n",
    "Music genres allow characterization of music to facilitate discussion by providing descriptive language regarding the music, helping musicians and industry personnel to understand audience preferences and listening habits and affects the creation and marketing of music.\n",
    "\n",
    "Successful classification of music by genre can provide help build pertinent recommendation systems to help music providers create playlists or streaming services which match the consumer's tastes and expectations. Many of these systems are based upon comparison of user's tastes but, for the purposes of this project, I chose to use Spotify music audio features exclusively to attempt to build a multi-classification system.\n",
    "\n",
    "The metrics provided by Spotify are shown below. Please see Spotify documentation for more specific details.\n",
    "\n",
    "- danceability - suitability for dancing based upon tempo, rhythm, beat and other factors.  Scale: 0.0 - 1.0\n",
    "- energy - perceptual measure of intensity and activity. Scale: 0.0 - 1.0\n",
    "- key - estimated overall key of track.  Scale: integer\n",
    "- loudness - the overall loudness of a track in decibels (dB).  This value will be converted to scalar 0.0-1.0\n",
    "- speechiness - detects the presence of spoken words in a track. . Scale: 0.0-1.0\n",
    "- acousticness - overall acousticness of track.  Most tracks are have low acousticness.  Scale: 0.0-1.0\n",
    "- instrumentalness - predicts whether a track contains no vocals. Scale: 0.0-1.0\n",
    "- liveness - detects the presence of an audience in the recording. Scale: 0.0-1.0\n",
    "- valence - describing the musical positiveness conveyed by a track.  Higher values are 'happier'.  Scale: 0.0-1.0\n",
    "- tempo - overall estimated tempo of a track in beats per minute (BPM).  This value will be converted to a scalar 0.0-1.0\n",
    "\n",
    "The analysis will compare the audio features of each genre to try to identify distinquishing characteristics, determine overlap between genres and build classification models to assign genre information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Used\n",
    "Description of data set and methodology to solve the problem:\n",
    "\n",
    "Analysis of music genres using data from Every Noise at Once, everynoise.com, a site dedicated to tracking music genres and Spotify API to extract audio features from various songs. While everynoise tracks thousands of genres, the following list of genres were chosen for this analysis:\n",
    "\n",
    "- Alternative Rock\n",
    "- Country\n",
    "- Dance Pop\n",
    "- Hip Hop\n",
    "- Pop\n",
    "- R&B\n",
    "- Rock\n",
    "\n",
    "Everynoise creates Spotify playlists associated with each genre listed. Using the Spotify API, the associated playlist names were found on Spotify, verified as being created by 'The Sound of Spotify', the user name of everynoise on Spotify.\n",
    "\n",
    "Everynoise creates playlists on Spotify for most of the genres the show on the website. Using the Spotify API, the pertinent playlists for the genres listed above were identified and the meta data for each track was saved to a csv file. After data cleanup and pre-processing, approxmately 5100 tracks were identified for the study.\n",
    "\n",
    "Using the saved csv file and the Spotify API, the audio features listed above were queried, converted from json format and saved as csv file. Csv files of the data were saved at various points in the analysis to preclude the neccessity of gerneating the data each time. The two sets of data (meta and audio features) were joined into a single data frame and saved as a csv.\n",
    "\n",
    "Some pre-processing was required, although many of the metrics used where already scalar, but some of the remaining metrics were converted to scalar values. After clean-up, several data visualizations were generated to help obtain a sense of the data. From this review, several metrics were identified as key indicators such as \"energy\", \"tempo\", \"loudness\", \"danceability\". Seperate OneVSRest dataframes were created and plotted against each of these key metrics.\n",
    "\n",
    "As a multi-classification project, four models were selected for evaluation K Nearest Neighbor (knn) Decision Tree (tree) Support Vector Machine (svm) Logristic OnevsRest (log)\n",
    "\n",
    "The data was split into a train and test set with 20% of the data reserved for testing. Each model was measured against a metric function which printed the confusion matrix, printed other metrics and a classification report. The data was also saved to a dataframe and ultimatley concatenated into a single data frame capturing all metrics.\n",
    "\n",
    "A K Means Clustering model was also applied against the same training and test data to see how the data itself would drive clustering without regard to pre-defined genre labels. This data was compared to the original genre data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
