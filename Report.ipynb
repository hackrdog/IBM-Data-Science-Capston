{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Data Science Capstone Project\n",
    "## Introduction\n",
    "Music genres allow characterization of music to facilitate discussion by providing descriptive language regarding the music, helping musicians and industry personnel to understand audience preferences and listening habits and affects the creation and marketing of music.\n",
    "\n",
    "Successful classification of music by genre can provide help build pertinent recommendation systems to help music providers create playlists or streaming services which match the consumer's tastes and expectations. Many of these systems are based upon comparison of user's tastes but, for the purposes of this project, I chose to use Spotify music audio features exclusively to attempt to build a multi-classification system.\n",
    "\n",
    "The metrics provided by Spotify are shown below. Please see Spotify documentation for more specific details.\n",
    "\n",
    "- danceability - suitability for dancing based upon tempo, rhythm, beat and other factors.  Scale: 0.0 - 1.0\n",
    "- energy - perceptual measure of intensity and activity. Scale: 0.0 - 1.0\n",
    "- key - estimated overall key of track.  Scale: integer\n",
    "- loudness - the overall loudness of a track in decibels (dB).  This value will be converted to scalar 0.0-1.0\n",
    "- speechiness - detects the presence of spoken words in a track. . Scale: 0.0-1.0\n",
    "- acousticness - overall acousticness of track.  Most tracks are have low acousticness.  Scale: 0.0-1.0\n",
    "- instrumentalness - predicts whether a track contains no vocals. Scale: 0.0-1.0\n",
    "- liveness - detects the presence of an audience in the recording. Scale: 0.0-1.0\n",
    "- valence - describing the musical positiveness conveyed by a track.  Higher values are 'happier'.  Scale: 0.0-1.0\n",
    "- tempo - overall estimated tempo of a track in beats per minute (BPM).  This value will be converted to a scalar 0.0-1.0\n",
    "\n",
    "The analysis will compare the audio features of each genre to try to identify distinquishing characteristics, determine overlap between genres and build classification models to assign genre information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Used\n",
    "Description of data set and methodology to solve the problem:\n",
    "\n",
    "Analysis of music genres using data from Every Noise at Once, everynoise.com, a site dedicated to tracking music genres and Spotify API to extract audio features from various songs. While everynoise tracks thousands of genres, the following list of genres were chosen for this analysis:\n",
    "\n",
    "- Alternative Rock\n",
    "- Country\n",
    "- Dance Pop\n",
    "- Hip Hop\n",
    "- Pop\n",
    "- R&B\n",
    "- Rock\n",
    "\n",
    "Everynoise creates Spotify playlists associated with each genre listed. Using the Spotify API, the associated playlist names were found on Spotify, verified as being created by 'The Sound of Spotify', the user name of everynoise on Spotify.\n",
    "\n",
    "Everynoise creates playlists on Spotify for most of the genres the show on the website. Using the Spotify API, the pertinent playlists for the genres listed above were identified and the meta data for each track was saved to a csv file. After data cleanup and pre-processing, approxmately 5100 tracks were identified for the study.\n",
    "\n",
    "Using the saved csv file and the Spotify API, the audio features listed above were queried, converted from json format and saved as csv file. Csv files of the data were saved at various points in the analysis to preclude the neccessity of gerneating the data each time. The two sets of data (meta and audio features) were joined into a single data frame and saved as a csv.\n",
    "\n",
    "Some pre-processing was required, although many of the metrics used where already scalar, but some of the remaining metrics were converted to scalar values. After clean-up, several data visualizations were generated to help obtain a sense of the data. From this review, several metrics were identified as key indicators such as \"energy\", \"tempo\", \"loudness\", \"danceability\". Seperate OneVSRest dataframes were created and plotted against each of these key metrics.\n",
    "\n",
    "As a multi-classification project, four models were selected for evaluation K Nearest Neighbor (knn) Decision Tree (tree) Support Vector Machine (svm) Logristic OnevsRest (log)\n",
    "\n",
    "The data was split into a train and test set with 20% of the data reserved for testing. Each model was measured against a metric function which printed the confusion matrix, printed other metrics and a classification report. The data was also saved to a dataframe and ultimatley concatenated into a single data frame capturing all metrics.\n",
    "\n",
    "A K Means Clustering model was also applied against the same training and test data to see how the data itself would drive clustering without regard to pre-defined genre labels. This data was compared to the original genre data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology section \n",
    "*The main component of the report where you discuss and describe any exploratory data analysis that you did, any inferential statistical testing that you performed, if any, and what machine learnings were used and why.*\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "I explored a few different sources of music genre classification - Billboard charts, Everynoise.com and LastFM.com.  All three sources contained detailed information about various genres which included lists or searchable API calls to extract the data.  After looking at the data, I decided to use Everynoise.com for my primary data sources.  I also selected music genres from the primary genres which are listened to today - alternative, rock, pop, hip-hop, r&b, country and dance.\n",
    "\n",
    "I scraped the data from the web site and saved the list of each genre listed above into a csv/excel data file.  My next step was to identify the songs from Everynoise and match them to a corresponding Spotify track ID to facilitate extraction the audio features for each track.  This was the messiest part of the data clean up within included several search passes through Spotify using the API to locate the Spotify ID.  The primary issue was naming conventions regarding artist names.  For the most part, I was able to identify 99% of the tracks on Spotify.  Using the Spotify ID, I called the audio features API for each song.  I ended up with 5141 tracks across all genres.  I joined the dataframes containing the genre information with the audio features and saved the output to a csv file.  The data is ready for analysis.\n",
    "\n",
    "I also created several data visuals to help understand the features and data.  The graph below shows the distribution of the danceability of each genre.  All feature graphs are available in the project notebook.\n",
    "<img src=\"all_plot_danceability.png\">\n",
    "\n",
    "I also created a series of graphs for each genre of the four primary features I expected would be significant in deriving the multi-classsication models.  These features are [\"energy\", \"tempo\", \"loudness\", \"danceability\"].  For these features, I created One vs. Other type data frames and plotted each genre against all others.  Later on I find that all models have difficulty with the Pop genre and you can tell from the Pop charts why the models might struggle.  All genre charts are available in the project notebook.\n",
    "<img src=\"genre_Pop.png\">\n",
    "\n",
    "### Models Used\n",
    "The problem was a supervised multi-class model with a small number of features and I did not know which model might perform best, so I decided to use 4 different models and let the results help select the appropraite model.  I split my data into train and testing sets using a 75/25 split. \n",
    "\n",
    "The first model was the K Nearest Neighbor (knn) model.  I ran the model using a Ks from 1-20 and found that a Ks value of 15 provided the best results.  I also noticed that the best module obtained a accuracy score of slightly less than 0.50.  This worried me as this is not a very high accuracy score, but I proceeded ahead.  \n",
    "\n",
    "To help compare results, I created a metrics function with analysed the predictions of each model the same way and returns the confusion matrix and classification report for each model.\n",
    "\n",
    "After developing the knn model, I used Decision Tree, Support Vector Machine and Logistic models using the same metrics.\n",
    "\n",
    "During the development of the model, I noticed that I obtained different results when I restarted the models from scratch.  I did not have enough data to segment the data into independent sets for analysis of the accuracy of the models, so I decided to run each model 100 times with near random creation of training and test data each time.  During this testing, I omitted the knn model as I was uncertain is the Ks = 15 assumption would be valid across all tests.  To streamline the analysis of the results, I focused on the confusion matrix and F1 score for each test.  I created box charts for the results of each genre by model.  I also created an average confusion matrix for each model and displayed the average confusion matrix.\n",
    "\n",
    "I also used the K Means Clustering (kmc) model to segment the music into clusters using pure audio feature data.  I then created a pivot displaying how the kmc model mapped to genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results section where you discuss the results.\n",
    "For the purposes of discussing results, I chose to focus on the aggregate results of 100 tests of each model.  The first metric used was the mean of the F1 score as shown below.\n",
    "### Logistic Model\n",
    "![](log_100_box1.png)\n",
    "### Decision Tree Model\n",
    "![](tree_100_box.png)\n",
    "### Support Vector Machine Model\n",
    "![](svm_100_box1.png)\n",
    "Clearly, this data shows all three models have significant issues predicting genre based upon just the audio features provided.  Country genre shows the highest predictability across all the models with an mean F1 score in the range of 0.71-0.75 across the models.  Dance and Hip-Hop score the next highest and provide relatively consistent results across all thre models with Dance means = 0.43, 0.51, 0.51 and Hip-Hop means = 0.46, 0.50, 0.50.  Alternative rock F1 scores vary from 0.38, 0.34 and 0.28, pretty poorly although all three models are fairly consistent.  For the remaining three genres, Rock, Pop and R&B, the models performed quite poorly with some substainial differences between the models.  The Decision tree model obtained F1 scores of 0.39 for Rock and 0.01 for R&B and Pop.  Essentially, the decision tree almost never predicted any song to belong to the Pop or R&B genre as shown in the confusion matrix discussion which follows.  The Logistic model F1 mean scores were Rock = 0.16, Pop = 0.30, R&B = 0.02.  SVM Model F1 mean scores were Rock = 0.16, Pop = 0.30, R&B = 0.00.  Essentially the Logistic and SVM provided nearly identical F1 scores.\n",
    "\n",
    "Review of the confusion matrix for each model shows\n",
    "### Logistic Model\n",
    "![](log_100_cm.png)\n",
    "### Decision Tree Model\n",
    "![](tree_100_cm.png)\n",
    "### Support Vector Machine Model\n",
    "![](svm_100_cm.png)\n",
    "### All Models\n",
    "![](all_100_cm.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion section where you discuss any observations you noted and any recommendations you can make based on the results.\n",
    "\n",
    "### Observations\n",
    "\n",
    "Looking at the *All Models Average* confusion matrix above, several observations about the models can be made.\n",
    "- The F1 scores and confusion matrix for all three models are consistent with each other with some minor differences across the genres.\n",
    "- All models tended to mis-classify Alternative music as Hip-Hop, with an average of 49% of all Alternative songs being classified as Hip-Hop\n",
    "- Country music has the most definitive feature variation with an overall F1 mean average of 76% across all three models.  The models were very accurate with low false positive rates in all other genres except Dance Pop (18%).\n",
    "- All models generated significant False Positive predictions in the Dance Pop category with high False Positive rates for Rock (39%), Pop (51%) and R&B (52%).  False Positives were significant in all remaining genres as well Alternative (15%), Country (18%) and Hip-Hop (20%).\n",
    "- All models under predicted Pop genre with 17% Accuracy and low F1 False Positive scores in all other genres.\n",
    "- All models rarely predicted R&B with R&B songs falsely attributed to Dance Pop (52%), Country (18%), Rock (12%) and the remaining 18% distributed across remaining genres.\n",
    "\n",
    "### Recommendations\n",
    "While providing useful information about tracks which may be useful in recommendation systems, the audio features provided by Spotify API do not provide enough variant data to properly classify the genre of the track.  The primary issue in the data seems to be the features associated with Dance Pop genre.  Looking at the chart for Dance Pop compared to all others,\n",
    "the overlap of this one genre over the entirity of other data is obvious.\n",
    "![](genre_Dance.png)\n",
    "\n",
    "Next steps should include finding additional features to add to the model to help discriminate across genres.  Two primary directions are available: audio signal analysis and lyric analysis.  Several good libraries, such as Librosa and PyAudio, exist to allow audio signal analysis.  This branch would analyze the spectogram of the audio track itself.  The frequency response of individual tracks could be converted to features for the model and added to the Spotify Audio features used here.  This branch of analysis would require audio samples of each track.\n",
    "\n",
    "The second branch of genre classification would include application of Natual Language Processing (NLP) to the lyrics.  Lyrics can be scrapped from various web sites, captured from Genius.com or kaggle.com has several datasets used in similar analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Work.\n",
    "The results of the model conclusively show that using audio features available through the Spotify API are insufficient to building a successful music genre classification system.  Perusing the topic on several data science topics, reveals that developing successful music classification algorithms is very difficult.  The problem lies potentially in a lack of clearly defined limits for each genre, popular tracks are increasingly blending genres and the similarity of topics of songs across all genres.\n",
    "\n",
    "No clear standards exist for classifying genres.  This study used a few genres selected from Everynoise.com, but this web site tracks over 4500 individual genres, with many songs mapping to multiple genres.  Additionally, songs are increasing crossing over traditional genre classifications.  The #1 Hot Billboard Song for 2019 was Old Town Road by Lil Nas X which could easily fit into either the Hip-Hop or Country genres.  Songs from all genres cover topics about love, relationships, trials and tribulations rendering subtle, hard to discriminate differences in lyric features.\n",
    "\n",
    "In my research, I have not come across models which combine lyric, Spotify audio features and spectrum analysis into a single model to see if a combined data set would provide higher accuracy in predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
